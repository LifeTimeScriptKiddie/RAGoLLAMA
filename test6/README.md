# ğŸ¦ Financial Advisor Suite

A comprehensive AI-powered financial advisor built with Docker, Docling, Ollama, TurboRAG, and CAG technologies. Features a 5-tab Streamlit interface for personalized financial advice, tax optimization, investment analysis, and document management.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINANCIAL ADVISOR SUITE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend: Streamlit (5 Tabs)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Smart    â”‚Tax      â”‚Invest-  â”‚Analyticsâ”‚Document         â”‚   â”‚
â”‚  â”‚Assistantâ”‚Dashboardâ”‚ments    â”‚         â”‚Manager          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Core Intelligence Layer                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚TurboRAG     â”‚CAG Engine   â”‚Ollama Clientâ”‚Document Manager â”‚ â”‚
â”‚  â”‚(Enhanced    â”‚(Context-    â”‚(LLM         â”‚(Auto Processing)â”‚ â”‚
â”‚  â”‚Retrieval)   â”‚Aware Gen)   â”‚Integration) â”‚                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Processing Layer                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Docling      â”‚Vector Store â”‚Stock API    â”‚Financial        â”‚ â”‚
â”‚  â”‚(PDF OCR)    â”‚(FAISS)      â”‚(Portfolio)  â”‚Analytics        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage Layer                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚SQLite       â”‚Vector       â”‚Document     â”‚Model            â”‚ â”‚
â”‚  â”‚(Transactionsâ”‚Embeddings   â”‚Files        â”‚Storage          â”‚ â”‚
â”‚  â”‚& Metadata)  â”‚             â”‚(/docs)      â”‚(Ollama)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ³ Docker Container Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Docker Network                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Streamlit     â”‚  â”‚     Ollama      â”‚  â”‚   Open WebUI    â”‚ â”‚
â”‚  â”‚   Container     â”‚  â”‚   Container     â”‚  â”‚   Container     â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ Port: 8501      â”‚  â”‚ Port: 11434     â”‚  â”‚ Port: 3000      â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ â€¢ Streamlit App â”‚  â”‚ â€¢ 5 LLM Models  â”‚  â”‚ â€¢ Web Interface â”‚ â”‚
â”‚  â”‚ â€¢ All Core      â”‚  â”‚ â€¢ API Server    â”‚  â”‚ â€¢ Model Mgmt    â”‚ â”‚
â”‚  â”‚   Components    â”‚  â”‚ â€¢ Model Storage â”‚  â”‚                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                     â”‚                     â”‚        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                 â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           Host Volumes          â”‚                              â”‚
â”‚                                 â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ./docs/       â”‚  â”‚ shared_models   â”‚  â”‚   ./data/       â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ â€¢ Cyber Docs    â”‚  â”‚ â€¢ Vector Store  â”‚  â”‚ â€¢ SQLite DB     â”‚ â”‚
â”‚  â”‚ â€¢ Financial     â”‚  â”‚ â€¢ Embeddings    â”‚  â”‚ â€¢ Logs          â”‚ â”‚
â”‚  â”‚ â€¢ General Docs  â”‚  â”‚ â€¢ FAISS Index   â”‚  â”‚ â€¢ Cache         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- 8GB+ RAM (5.5GB+ available for containers)
- 10GB+ disk space

### ğŸ³ Docker Deployment Options

#### **Option 1: Development (Quick Start)**
```bash
# Clone and start immediately
git clone https://github.com/LifeTimeScriptKiddie/RAGoLLAMA.git
cd RAGoLLAMA/test5_turborag_CAG

# One-line deployment
docker compose up -d && bash pull_models.sh
```

#### **Option 2: Production Ready**
```bash
# Automated production deployment
./deploy.sh -e production

# Manual production deployment
docker compose -f docker-compose.prod.yml up -d
bash pull_models.sh
```

#### **Option 3: Production with Nginx Proxy**
```bash
# Single entry point with reverse proxy
./deploy.sh -e production -p production -n

# Access all services through http://localhost
```

#### **Option 4: Cloud Deployment**
```bash
# For AWS, GCP, Azure with monitoring
docker compose -f docker-compose.cloud.yml --profile monitoring up -d
```

### ğŸŒ Service Access Points
- **Open WebUI (Chat)**: http://localhost:3000
- **Streamlit (Dashboard)**: http://localhost:8501
- **Knowledge Base API**: http://localhost:8502
- **Ollama API**: http://localhost:11434

### ğŸ“‹ Deployment Script Options
```bash
./deploy.sh --help                    # Show all options
./deploy.sh                          # Development deployment
./deploy.sh -e production             # Production deployment  
./deploy.sh -e production -n          # Production + Nginx proxy
./deploy.sh --no-models               # Skip model installation
```

### Adding Documents
Place documents in organized folders within `./docs/`. They will be automatically processed:
- **At startup**: All existing documents from all folders
- **Daily at 2AM**: New documents added to any folder
- **Manual scan**: Use the "Document Manager" tab

**Organized Document Structure:**
- `./docs/cyber/` - Cybersecurity, malware analysis, penetration testing materials
- `./docs/financial/` - Financial statements, tax documents, investment guides  
- `./docs/` (root) - General purpose documents and reference materials

## ğŸ§  Core Intelligence Components

### 1. TurboRAG (Enhanced Retrieval)
**Location**: `core/turbo_rag.py`

Enhanced retrieval-augmented generation with:
- **Semantic re-ranking** using sentence transformers
- **Combined scoring** (vector distance + semantic similarity)
- **Confidence calculation** based on retrieval scores
- **Source attribution** for transparency

```python
def retrieve_and_rank(self, query: str, k: int = 5):
    # 1. Get initial results from vector store (2x candidates)
    # 2. Re-rank using semantic similarity
    # 3. Combine original + semantic scores
    # 4. Return top-k ranked results
```

### 2. CAG Engine (Context-Aware Generation)
**Location**: `core/cag_engine.py`

Context-aware generation with conversation memory:
- **Financial context integration** (SQLite transaction data)
- **User profile personalization** (risk tolerance, age, income)
- **Conversation memory** (last 10 exchanges)
- **Query classification** (financial vs. general)

```python
def generate_context_aware_response(self, query: str, context_type: str):
    # 1. Get RAG results from TurboRAG
    # 2. Build context (financial data + user profile + conversation history)
    # 3. Generate enhanced prompt with all context
    # 4. Get LLM response via Ollama
    # 5. Update conversation history
```

### 3. Ollama Client (LLM Integration)
**Location**: `core/ollama_client.py`

Intelligent model management with:
- **Automatic model detection** on startup
- **Intelligent fallback hierarchy** (llama3.2:1b â†’ phi3 â†’ etc.)
- **Connection health monitoring**
- **Error handling** with user-friendly messages

### 4. Document Manager (Auto Processing)
**Location**: `core/document_manager.py`

Automated document lifecycle management:
- **SQLite tracking** (filename, hash, status, metadata)
- **Startup auto-processing** (all docs on first run)
- **Scheduled processing** (2AM daily via Python `schedule`)
- **Duplicate detection** (file hash comparison)
- **Comprehensive logging**

## ğŸ“Š Data Flow Architecture

### Document Processing Pipeline
```
PDF File â†’ Docling (OCR) â†’ Text Chunks â†’ Embeddings â†’ FAISS Vector Store
    â†“              â†“           â†“            â†“              â†“
File Hash â†’ SQLite Record â†’ Vector Index â†’ Search Ready â†’ RAG Retrieval
```

### Query Processing Pipeline
```
User Query â†’ Query Classification â†’ TurboRAG Retrieval â†’ Context Building â†’ CAG Generation
     â†“              â†“                    â†“                    â†“              â†“
Chat Interface â†’ Financial/General â†’ Ranked Sources â†’ Enhanced Prompt â†’ LLM Response
```

### Financial Data Pipeline
```
Bank Statement â†’ Statement Parser â†’ Transaction Categorization â†’ SQLite Storage
      â†“               â†“                      â†“                      â†“
Tax Analysis â†’ Business Classification â†’ Analytics Engine â†’ Insights & Recommendations
```

## ğŸ¯ 5-Tab Streamlit Interface

### Tab 1: ğŸ¤– Smart Assistant
- **Chat interface** with context-aware responses
- **Document upload** for immediate processing
- **Ollama model management** and status
- **User profile** setup for personalization

### Tab 2: ğŸ“Š Tax Dashboard
- **Statement upload** (PDF/CSV/OFX)
- **Transaction categorization** and business tagging
- **Tax optimization** suggestions
- **Financial insights** and deduction analysis

### Tab 3: ğŸ“ˆ Investments
- **Stock quotes** with real-time data
- **Portfolio analysis** with gain/loss calculations
- **Investment recommendations** by risk tolerance
- **Sample portfolio** analysis for demonstration

### Tab 4: ğŸ“Š Analytics
- **Spending analysis** with category breakdowns
- **Budget recommendations** with savings targets
- **Tax optimization insights**
- **Comprehensive financial reports**

### Tab 5: ğŸ“š Document Manager
- **Document status** overview with processing logs
- **Manual operations** (scan, clear, export)
- **Processing statistics** and error tracking
- **System instructions** and file type support

## ğŸ”§ Optimized Model Collection

### Memory-Optimized for 5.5GB Systems
```
qwen2.5:0.5b    (397MB)  â†’ Ultra-fast responses
tinyllama       (637MB)  â†’ Lightweight general tasks  
llama3.2:1b     (1.3GB)  â†’ RECOMMENDED DEFAULT
codegemma:2b    (1.6GB)  â†’ Programming & technical
phi3:latest     (2.2GB)  â†’ Most capable analysis
                -------
Total:          6.1GB    â†’ Only 1 runs at a time
```

The `pull_models.sh` script automatically installs this optimized collection based on your system's memory constraints.

## ğŸ›¡ï¸ Error Handling & Resilience

### Docling Fallback Chain
```
Docling OCR â†’ PyPDF2 â†’ pdfminer â†’ Text File â†’ Binary + UTF-8 Decode
```

### Ollama Model Fallback
```
Requested Model â†’ Default Model â†’ First Available â†’ Error Message
```

### Database Resilience
```
SQLite Connection â†’ Check Table Exists â†’ Create if Missing â†’ Graceful Degradation
```

## ğŸ“ Project Structure

```
test5_turborag_CAG/
â”œâ”€â”€ core/                           # Core intelligence components
â”‚   â”œâ”€â”€ cag_engine.py              # Context-aware generation
â”‚   â”œâ”€â”€ turbo_rag.py               # Enhanced RAG with re-ranking
â”‚   â”œâ”€â”€ ollama_client.py           # LLM integration
â”‚   â”œâ”€â”€ document_manager.py        # Auto document processing
â”‚   â”œâ”€â”€ stock_api.py               # Investment analysis
â”‚   â”œâ”€â”€ ingestion.py               # Document ingestion with fallbacks
â”‚   â”œâ”€â”€ vector_store.py            # FAISS vector operations
â”‚   â”œâ”€â”€ statement_parser.py        # Financial statement parsing
â”‚   â”œâ”€â”€ categorizer.py             # Transaction categorization
â”‚   â””â”€â”€ tax_optimizer.py           # Tax optimization engine
â”œâ”€â”€ financial_advisor/             # Streamlit application
â”‚   â”œâ”€â”€ app.py                     # Main 5-tab interface
â”‚   â””â”€â”€ analytics.py               # Financial analytics engine
â”œâ”€â”€ docs/                          # Document storage (auto-processed)
â”‚   â”œâ”€â”€ cyber/                     # Cybersecurity & malware analysis docs
â”‚   â”œâ”€â”€ financial/                 # Financial statements & tax documents
â”‚   â””â”€â”€ [general files]            # Other reference materials
â”œâ”€â”€ data/                          # SQLite database and logs
â”œâ”€â”€ docker-compose.yml             # Container orchestration
â”œâ”€â”€ pull_models.sh                 # Optimized model installer
â”œâ”€â”€ .gitignore                     # Git ignore rules
â””â”€â”€ README.md                      # This file
```

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file:
```env
# Optional: Stock API key for live data
ALPHA_VANTAGE_API_KEY=your_api_key_here

# Optional: Ollama configuration
OLLAMA_BASE_URL=http://ollama:11434
```

### Model Configuration
Edit `core/ollama_client.py` to modify the model preference hierarchy:
```python
preferred_models = [
    "llama3.2:latest", "llama3.2", "llama3.1:latest",
    "phi3:latest", "phi3", "gemma:latest", "gemma",
    "qwen:latest", "qwen", "mistral:latest", "mistral"
]
```

## ğŸš€ Usage Examples

### 1. Financial Advice Chat
```
User: "How much should I save for retirement at age 30?"
Assistant: Based on your profile (age 30, $50k income), I recommend...
```

### 2. Document Analysis
```
User: "What does my uploaded tax document say about deductions?"
Assistant: I found several deductible expenses in your document...
```

### 3. Investment Analysis
```
User: "Analyze my portfolio risk for aggressive investor"
Assistant: Your portfolio shows 65% growth stocks, 25% bonds...
```

### 4. Tax Optimization
```
Upload bank statement â†’ Automatic categorization â†’ Tax insights
"You could save $1,200 in taxes by optimizing business meal deductions"
```

## ğŸ³ Docker Deployment Configurations

### ğŸ“‹ Available Configurations

| Configuration | Purpose | Features | Use Case |
|---------------|---------|----------|----------|
| `docker-compose.yml` | Development | Hot reload, easy debugging | Local development |
| `docker-compose.prod.yml` | Production | Health checks, resource limits, security | Production deployment |
| `docker-compose.cloud.yml` | Cloud | Auto-scaling, monitoring, SSL | AWS/GCP/Azure |
| `nginx.conf` | Reverse Proxy | Single entry point, SSL termination | Production with proxy |

### ğŸš€ Deployment Environments

#### **Development Environment**
- **Purpose**: Local development and testing
- **Features**: Direct port access, easy debugging
- **Command**: `docker compose up -d`
- **Ports**: 3000 (WebUI), 8501 (Streamlit), 8502 (API), 11434 (Ollama)

#### **Production Environment**
- **Purpose**: Production deployment with enhanced security
- **Features**: Authentication enabled, health checks, resource limits
- **Command**: `./deploy.sh -e production`
- **Security**: Read-only mounts, restart policies, authentication required

#### **Cloud Environment**
- **Purpose**: Cloud platform deployment (AWS, GCP, Azure)
- **Features**: Auto-scaling, monitoring, external load balancer support
- **Command**: `docker compose -f docker-compose.cloud.yml up -d`
- **Optional**: Redis caching, PostgreSQL, Prometheus monitoring

### ğŸ”§ Resource Requirements

| Environment | CPU | RAM | Disk | Network |
|-------------|-----|-----|------|---------|
| **Development** | 4 cores | 8GB | 20GB | Local |
| **Production** | 8 cores | 16GB | 50GB SSD | 1Gbps |
| **Cloud** | 4-16 cores | 16-32GB | 100GB+ | Load balanced |

### ğŸ“Š Recommended Cloud Instances

| Provider | Instance Type | vCPUs | RAM | Use Case |
|----------|---------------|-------|-----|----------|
| **AWS** | t3.xlarge | 4 | 16GB | Small production |
| **AWS** | m5.xlarge | 4 | 16GB | Balanced workload |
| **AWS** | m5.2xlarge | 8 | 32GB | High performance |
| **GCP** | n2-standard-4 | 4 | 16GB | Small production |
| **GCP** | e2-standard-4 | 4 | 16GB | Cost-optimized |
| **Azure** | Standard_D4s_v3 | 4 | 16GB | General purpose |

### ğŸŒ Open WebUI Integration

#### **Method 1: Upload Functions (Recommended)**
1. Access Open WebUI at http://localhost:3000
2. Go to **Settings** â†’ **Functions**
3. Upload functions from `openwebui_functions/`:
   - `simple_financial_search.py` - Basic document search
   - `kb_status_checker.py` - Knowledge base status
   - `financial_advisor_kb.py` - Advanced features

#### **Method 2: Knowledge Base API Integration**
- **API Endpoint**: http://localhost:8502
- **Search**: `/search?query=malware&limit=3`
- **Status**: `/knowledge`
- **Documents**: `/documents`

#### **Method 3: Native Open WebUI Knowledge Base**
1. In Open WebUI, go to **Knowledge** section
2. Create knowledge base: "Financial Advisor Documents"
3. Upload documents from `docs/cyber/` and `docs/financial/`

### ğŸ” Production Security Checklist

- âœ… **Authentication**: Enable WebUI authentication (`WEBUI_AUTH=True`)
- âœ… **Secret Keys**: Set strong `WEBUI_SECRET_KEY`
- âœ… **Network**: Configure firewall rules
- âœ… **SSL/TLS**: Set up HTTPS with certificates
- âœ… **Updates**: Regular security updates
- âœ… **Backups**: Automated data backups
- âœ… **Monitoring**: Health checks and alerting

### ğŸ“ˆ Scaling and Monitoring

#### **Horizontal Scaling**
```bash
# Scale Financial Advisor service
docker compose up -d --scale financial_advisor=3
```

#### **Monitoring Stack**
```bash
# Deploy with Prometheus and Grafana
docker compose -f docker-compose.cloud.yml --profile monitoring up -d

# Access monitoring
# Grafana: http://localhost:3000
# Prometheus: http://localhost:9090
```

#### **Health Monitoring**
```bash
# Check all service health
curl http://localhost/health

# Individual health checks
curl http://localhost:8501/_stcore/health  # Streamlit
curl http://localhost:8502/               # Knowledge Base API
curl http://localhost:11434/api/version   # Ollama
```

### ğŸ”„ Backup and Recovery

#### **Data Volumes**
```bash
# List volumes to backup
docker volume ls | grep financial

# Backup critical data
docker run --rm -v shared_models:/data -v $(pwd):/backup alpine tar czf /backup/models.tar.gz -C /data .
docker run --rm -v openwebui_data:/data -v $(pwd):/backup alpine tar czf /backup/webui.tar.gz -C /data .
```

#### **Recovery Process**
```bash
# Restore from backup
docker volume create shared_models
docker run --rm -v shared_models:/data -v $(pwd):/backup alpine tar xzf /backup/models.tar.gz -C /data
```

## ğŸ” Troubleshooting

### Model Issues
```bash
# Check available models
docker exec test5_turborag_cag-ollama-1 ollama list

# Pull specific model
docker exec test5_turborag_cag-ollama-1 ollama pull llama3.2:1b

# Check model memory usage
docker stats
```

### Document Processing Issues
1. Check the **Document Manager** tab for processing logs
2. Verify PDF files are in `./docs/` folder
3. Check container logs: `docker logs test5_turborag_cag-financial_advisor-1`

### Container Issues
```bash
# Check all containers
docker compose ps

# Restart specific service
docker compose restart financial_advisor

# View logs
docker compose logs -f
```

### Deployment Issues

#### **Out of Memory Errors**
```bash
# Check memory usage
docker stats

# Free up memory
docker system prune -a

# Use smaller models
# Edit pull_models.sh to remove large models
```

#### **Port Conflicts**
```bash
# Check port usage
netstat -tlnp | grep :3000

# Change ports in docker-compose.yml
ports:
  - "3001:8080"  # Changed from 3000:8080
```

#### **SSL Certificate Issues**
```bash
# Generate self-signed certificate for testing
mkdir -p ssl
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout ssl/key.pem -out ssl/cert.pem \
  -subj "/C=US/ST=State/L=City/O=Organization/CN=localhost"
```

#### **Cloud Deployment Issues**
```bash
# Check cloud instance resources
top
df -h
free -h

# Verify network connectivity
curl -I http://localhost:3000
curl -I http://localhost:8501

# Check cloud provider firewall/security groups
# Ensure ports 80, 443, 3000, 8501 are open
```

#### **Performance Issues**
```bash
# Monitor resource usage
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# Optimize model selection
docker exec test5_turborag_cag-ollama-1 ollama list

# Scale services if needed
docker compose up -d --scale financial_advisor=2
```

## ğŸ³ Complete Deployment Summary

### ğŸ¯ **Deployment Options Comparison**

| Feature | Development | Production | Cloud | 
|---------|-------------|------------|--------|
| **Setup Complexity** | â­ Simple | â­â­ Medium | â­â­â­ Advanced |
| **Security** | Basic | Enhanced | Enterprise |
| **Monitoring** | Logs only | Health checks | Full stack |
| **Scalability** | Single instance | Multi-instance | Auto-scaling |
| **SSL/HTTPS** | No | Optional | Required |
| **Backup** | Manual | Automated | Cloud backup |
| **Cost** | Free | Low | Variable |

### ğŸš€ **Quick Deploy Commands**

```bash
# ğŸ”§ Development (Current setup)
docker compose up -d && bash pull_models.sh

# ğŸ­ Production
./deploy.sh -e production

# ğŸŒ Production with Proxy
./deploy.sh -e production -p production -n

# â˜ï¸ Cloud with Monitoring  
docker compose -f docker-compose.cloud.yml --profile monitoring up -d

# ğŸ”„ Update deployment
docker compose pull && docker compose up -d --force-recreate
```

### ğŸ“Š **Post-Deployment Verification**

```bash
# âœ… Check all services
curl http://localhost:3000    # Open WebUI
curl http://localhost:8501    # Streamlit  
curl http://localhost:8502    # Knowledge Base API
curl http://localhost:11434   # Ollama API

# âœ… Verify models loaded
docker exec test5_turborag_cag-ollama-1 ollama list

# âœ… Check document processing
curl http://localhost:8502/knowledge | jq '.total_documents'

# âœ… Test knowledge base integration
# Upload kb_status_checker.py to Open WebUI and ask "What's my knowledge base status?"
```

### ğŸ‰ **Success Indicators**

Your deployment is successful when:
- âœ… All containers show "healthy" status
- âœ… Open WebUI loads at http://localhost:3000  
- âœ… Streamlit dashboard loads at http://localhost:8501
- âœ… Knowledge Base API responds at http://localhost:8502
- âœ… 56+ documents are processed and searchable
- âœ… LLM models respond to queries
- âœ… Open WebUI functions can access your document knowledge base

## ğŸ—ï¸ Development

### Adding New Features
1. **Core Intelligence**: Add to `core/` directory
2. **UI Components**: Modify `financial_advisor/app.py`
3. **Analytics**: Extend `financial_advisor/analytics.py`

### Testing Document Processing
```bash
python test_ingestion.py
```

### Adding New Models
1. Edit `pull_models.sh` to add new models
2. Update fallback hierarchy in `core/ollama_client.py`
3. Test memory usage with `docker stats`

## ğŸ“ˆ Performance Optimization

### Memory Management
- Only one LLM model loads at a time
- Document embeddings cached in FAISS
- SQLite for lightweight data storage
- Automatic cleanup of temporary files

### Processing Speed
- TurboRAG re-ranking for better results
- Cached embeddings for faster retrieval
- Background document processing
- Efficient vector operations

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make changes and test thoroughly
4. Commit: `git commit -m "Add feature-name"`
5. Push: `git push origin feature-name`
6. Create a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Docling** for advanced PDF processing with OCR
- **Ollama** for local LLM inference
- **Streamlit** for the interactive web interface
- **FAISS** for efficient vector search
- **Sentence Transformers** for embeddings
- **Claude Code** for development assistance

## ğŸ“ Support

For issues and questions:
1. Check the **Document Manager** tab for system status
2. Review container logs: `docker compose logs`
3. Create an issue on GitHub with system details

---

**ğŸ¯ Built for memory-efficient systems while providing enterprise-level financial advisory capabilities!**