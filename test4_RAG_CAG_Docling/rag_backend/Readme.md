Here‚Äôs your ‚úÖ Final README.md ‚Äî cleaned up, modular, and updated to reflect Streamlit and non-Streamlit use cases, Open WebUI, and flexible embedding modes.

‚∏ª

‚úÖ Local RAG Chatbot with Ollama, Docling, and Open WebUI

This project is a fully local Retrieval-Augmented Generation (RAG) system using:
	‚Ä¢	üß† Ollama for running open-source LLMs locally
	‚Ä¢	üìÑ Docling for smart PDF/Markdown/Doc chunking
	‚Ä¢	üîç sentence-transformers or Ollama for embeddings
	‚Ä¢	üåê Open WebUI as the optional document/chat frontend
	‚Ä¢	‚öôÔ∏è Optional Streamlit app (main.py) for lightweight local UI

‚∏ª

üìÅ Project Structure

project-root/
‚îú‚îÄ‚îÄ api.py              # Prompt handler for Ollama / Open WebUI
‚îú‚îÄ‚îÄ config.py           # Loads .env configs
‚îú‚îÄ‚îÄ doc_processor.py    # Uses Docling to chunk docs
‚îú‚îÄ‚îÄ vectorizer.py       # Embeds chunks using local SentenceTransformer
‚îú‚îÄ‚îÄ ollama_embed.py     # Optional: Ollama-based LangChain embedding wrapper
‚îú‚îÄ‚îÄ uploader.py         # Syncs files to Open WebUI knowledge base
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ .env


‚∏ª

üß† Modes of Operation

1. Streamlit UI (for testing)

streamlit run main.py

2. Open WebUI + CLI Backend

Use uploader.py, doc_processor.py, and api.py to embed docs and sync with WebUI.

‚∏ª

üîÑ Architecture Diagram

‚úÖ Docker Build & Execution Flow

```mermaid
graph TD

A[User runs: docker-compose up] --> B[Dockerfile in backend]
B --> C[Install Python + Requirements]
C --> D[Copy all source files into /app]
D --> E[Set CMD: python uploader.py or Streamlit]

E --> F[Streamlit or CLI script runs]
F --> G[PDF/doc loaded via Docling (doc_processor.py)]
G --> H[Chunks embedded via vectorizer.py or ollama_embed.py]
H --> I[User query handled by api.py]
I --> J[Ollama queried and response returned]
```

‚∏ª

üìÑ Breakdown by Script

Script	Role
main.py	Optional Streamlit front-end UI (can be removed)
doc_processor.py	Loads documents using Docling
vectorizer.py	Embeds using local SentenceTransformer
ollama_embed.py	LangChain-compatible wrapper to use Ollama‚Äôs embedding API
api.py	Queries Ollama or Open WebUI
config.py	Loads .env settings
uploader.py	Uploads .pdf, .md, .docx, .jpg, etc. to Open WebUI
requirements.txt	Python dependencies
Dockerfile	Backend container image
docker-compose.yml	Optional container orchestration


‚∏ª

üß† Install Ollama

brew install ollama
ollama serve

# Pull desired models
ollama pull llama3
ollama pull mistral
ollama pull codellama:7b
ollama pull phi3

# Run a model
ollama run llama3


‚∏ª

üê≥ Docker Commands

# Build and run
docker compose up --build -d

# Stop
docker compose down

# Clean everything
docker compose down --volumes --remove-orphans
docker system prune -af --volumes


‚∏ª

üåê Interfaces

Component	URL
Streamlit App	http://localhost:8501
Open WebUI	http://localhost:3000
Ollama API	http://localhost:11434


‚∏ª

‚öôÔ∏è .env Configuration

Example .env:

OLLAMA_URL=http://localhost:11434
OPEN_WEBUI_URL=http://localhost:3000
OPEN_WEBUI_TOKEN=Bearer your_openwebui_token
EMBED_MODEL=all-MiniLM-L6-v2


‚∏ª

‚úÖ Notes
	‚Ä¢	Works fully offline (as long as Ollama and models are pre-pulled).
	‚Ä¢	Supports all major doc types: .pdf, .md, .docx, .txt, .html, .csv, .jpg, .png, etc.
	‚Ä¢	Use vectorizer.py for local embedding OR ollama_embed.py to use Ollama.
	‚Ä¢	main.py is optional ‚Äî you can fully operate through CLI and Open WebUI.
	‚Ä¢	Flexible and extendable for LangChain, Flask, FastAPI, or scheduled pipelines.

‚∏ª